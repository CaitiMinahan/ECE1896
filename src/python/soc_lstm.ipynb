{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Long short-term memory (LSTM) for Battery Management System (BMS) State of Charge (SOC) and State of Health (SOH) Estimation\n",
    "\n",
    "<img src=\"../../doc/img/LSTMNetwork.jpg\" height=\"530\"\n",
    "     alt=\"Machine Learning Network\"\n",
    "     style=\"fit: left; margin-right: 10px;\"  />"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ede2fd9ea9a82e5"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Import Libraries"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d6a4133cfdb0184d"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Caiti\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# adding new libraries\n",
    "import tensorflow as tf \n",
    "from tensorflow.keras.models import Sequential \n",
    "from tensorflow.keras.layers import Flatten \n",
    "from tensorflow.keras.layers import Dense, Dropout \n",
    "from tensorflow.keras.layers import Activation \n",
    "from tensorflow.keras import layers, Input\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler  \n",
    "from tensorflow.keras.optimizers import Adam\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-11T19:13:35.135528600Z",
     "start_time": "2024-02-11T19:13:17.340715100Z"
    }
   },
   "id": "3bb5f57e7bcf1ed4",
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Import Data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "382394fc93f24d78"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-02-11T19:13:46.920152Z",
     "start_time": "2024-02-11T19:13:45.366653500Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "                  V             I           SOC        T_surf           SOH\ncount  1.640946e+06  1.640946e+06  1.640946e+06  1.640946e+06  1.640946e+06\nmean   3.471013e+00  3.610140e+00  4.188879e+01  5.180549e+01  8.566437e+01\nstd    8.445745e-01  2.830966e+01  4.022232e+01  2.451698e+01  9.026790e+00\nmin   -9.394656e-01 -5.500295e+01 -5.753759e+00  2.499965e+01  7.000000e+01\n25%    3.144859e+00 -1.900000e+01  1.230206e+00  2.583835e+01  7.800000e+01\n50%    3.693897e+00  5.000000e+00  3.474387e+01  4.826449e+01  8.600000e+01\n75%    4.064538e+00  2.600000e+01  8.456010e+01  7.304868e+01  9.400000e+01\nmax    4.723157e+00  5.500289e+01  1.070423e+02  1.015903e+02  1.000000e+02",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>V</th>\n      <th>I</th>\n      <th>SOC</th>\n      <th>T_surf</th>\n      <th>SOH</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>1.640946e+06</td>\n      <td>1.640946e+06</td>\n      <td>1.640946e+06</td>\n      <td>1.640946e+06</td>\n      <td>1.640946e+06</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>3.471013e+00</td>\n      <td>3.610140e+00</td>\n      <td>4.188879e+01</td>\n      <td>5.180549e+01</td>\n      <td>8.566437e+01</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>8.445745e-01</td>\n      <td>2.830966e+01</td>\n      <td>4.022232e+01</td>\n      <td>2.451698e+01</td>\n      <td>9.026790e+00</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>-9.394656e-01</td>\n      <td>-5.500295e+01</td>\n      <td>-5.753759e+00</td>\n      <td>2.499965e+01</td>\n      <td>7.000000e+01</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>3.144859e+00</td>\n      <td>-1.900000e+01</td>\n      <td>1.230206e+00</td>\n      <td>2.583835e+01</td>\n      <td>7.800000e+01</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>3.693897e+00</td>\n      <td>5.000000e+00</td>\n      <td>3.474387e+01</td>\n      <td>4.826449e+01</td>\n      <td>8.600000e+01</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>4.064538e+00</td>\n      <td>2.600000e+01</td>\n      <td>8.456010e+01</td>\n      <td>7.304868e+01</td>\n      <td>9.400000e+01</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>4.723157e+00</td>\n      <td>5.500289e+01</td>\n      <td>1.070423e+02</td>\n      <td>1.015903e+02</td>\n      <td>1.000000e+02</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import Data\n",
    "df = pd.read_csv('../../res/model_data/batemo_model_data.csv')\n",
    "df.describe()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Train Test Split"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f43256173a46820c"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1312755, 1, 2)\n",
      "(1312755, 2)\n",
      "(328189, 1, 2)\n",
      "(328189, 2)\n"
     ]
    }
   ],
   "source": [
    "# Define training variables\n",
    "# TODO: need to consider if keeping current (I) is a valuable input feature or not (test if the model performs better w/o it)\n",
    "X = df[['V', 'I']].values\n",
    "\n",
    "# LSTM output with 2 nodes (SOH and SOC) \n",
    "Y = df[['SOC', 'SOH']].values\n",
    "\n",
    "# Normalize input data\n",
    "scaler = MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Split the data into training and testing\n",
    "x_train, x_test, y_train, y_test = train_test_split(X_scaled, Y, test_size=0.2, random_state=42)  # use normalized features to prevent over-fitting (X_scaled)\n",
    "\n",
    "# Define function to create sequences\n",
    "# NOTE: The creation of input-output pairs allows the model to learn from historical context. The input sequences serve as a history of past observations, while the corresponding output (target) provides the next observation in the sequence.This historical context is crucial for making accurate predictions, especially in time-series forecasting or sequence prediction tasks where the future state depends on past states\n",
    "def create_sequences(data, seq_length):\n",
    "    X = []\n",
    "    y = []\n",
    "    for i in range(len(data) - seq_length):\n",
    "        X.append(data[i:i + seq_length])  # Features (voltage, current, temperature, state of charge) are turned into a list of historical values \n",
    "        y.append(data[i + seq_length])     # Target variables (SOH and SOC) are turned into a list of historical values \n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# Choose sequence length\n",
    "seq_length = 1 # sequence length set to 1 to take immediate values from sensor reading during testing \n",
    "# NOTE:  Even with seq_length of 1, organizing the data into sequences might provide the model with some historical context. Although the immediate historical context is limited, the model can still potentially learn from patterns and trends in the data over time\n",
    "# TODO: may need to increase the sequence length if the model performs poorly on testing (sensor) data \n",
    "\n",
    "# Create sequences for training and testing data\n",
    "X_train_seq, y_train_seq = create_sequences(x_train, seq_length)\n",
    "X_test_seq, y_test_seq = create_sequences(x_test, seq_length)\n",
    "\n",
    "print(X_train_seq.shape)\n",
    "print(y_train_seq.shape)\n",
    "print(X_test_seq.shape)\n",
    "print(y_test_seq.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-11T19:13:59.201844100Z",
     "start_time": "2024-02-11T19:13:55.980580600Z"
    }
   },
   "id": "fec8c5f154adcc8a",
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Fit Model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bca6a6d9d787af94"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Caiti\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "WARNING:tensorflow:From C:\\Users\\Caiti\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 50)                10600     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 2)                 102       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10702 (41.80 KB)\n",
      "Trainable params: 10702 (41.80 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:From C:\\Users\\Caiti\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "41024/41024 [==============================] - 101s 2ms/step - loss: 0.0451 - val_loss: 0.0444\n",
      "Epoch 2/10\n",
      "41024/41024 [==============================] - 95s 2ms/step - loss: 0.0443 - val_loss: 0.0444\n",
      "Epoch 3/10\n",
      "41024/41024 [==============================] - 96s 2ms/step - loss: 0.0443 - val_loss: 0.0444\n",
      "Epoch 4/10\n",
      "41024/41024 [==============================] - 96s 2ms/step - loss: 0.0442 - val_loss: 0.0444\n",
      "Epoch 5/10\n",
      "41024/41024 [==============================] - 95s 2ms/step - loss: 0.0442 - val_loss: 0.0443\n",
      "Epoch 6/10\n",
      "41024/41024 [==============================] - 96s 2ms/step - loss: 0.0442 - val_loss: 0.0443\n",
      "Epoch 7/10\n",
      "41024/41024 [==============================] - 96s 2ms/step - loss: 0.0442 - val_loss: 0.0443\n",
      "Epoch 8/10\n",
      "41024/41024 [==============================] - 95s 2ms/step - loss: 0.0442 - val_loss: 0.0443\n",
      "Epoch 9/10\n",
      "41024/41024 [==============================] - 94s 2ms/step - loss: 0.0442 - val_loss: 0.0444\n",
      "Epoch 10/10\n",
      "41024/41024 [==============================] - 97s 2ms/step - loss: 0.0442 - val_loss: 0.0444\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.src.callbacks.History at 0x18ac7dc46a0>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define model for predicting SOH and SOC \n",
    "model = Sequential()\n",
    "\n",
    "# Defining a model for predicting SOH and SOC\n",
    "model.add(LSTM(50, activation='relu', input_shape=(X_train_seq.shape[1], X_train_seq.shape[2])))\n",
    "\n",
    "model.add(Dense(units=2))  # Output layer for two continuous values: SOC and SOH\n",
    "\n",
    "# Compile model with Adam optimizer and default learning rate\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# NOTE: .summary() is a method used in Keras, a high-level deep learning library, to display a summary of the neural network model's architecture. it will print out the layer name, layer type, output shape, number of parameters and trainable/non-trainable params\n",
    "model.summary()\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train_seq, y_train_seq, epochs=10, batch_size=32, validation_data=(X_test_seq, y_test_seq))\n",
    "\n",
    "# TODO: THINGS TO CONSIDER FOR FINE-TUNING HYPERPARAMETERS\n",
    "# TODO: 1) consider altering the depth of the network. currently we have 1 hidden layer \n",
    "# TODO: 2) consider altering the width of the network. currently there are 50 nodes \n",
    "# TODO: 3) consider altering the activation function. right now it is set to be relu \n",
    "# TODO: 4) consider altering the optimizer. right now it is set to Adam\n",
    "# TODO: 5) consider altering the number of epochs "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-11T19:30:04.783407600Z",
     "start_time": "2024-02-11T19:14:03.920946600Z"
    }
   },
   "id": "940d00ddbf62df1c",
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Test Model / Predict"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f1eb6fef4085f143"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10256/10256 [==============================] - 18s 2ms/step - loss: 0.0444\n",
      "Test Loss: 0.04435176029801369\n",
      "10256/10256 [==============================] - 16s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "# Preprocess and create sequences for new data\n",
    "# TODO: once loaded onto the microcontroller, new_data will be the sensor reading \n",
    "# new_data_scaled = scaler.transform(new_data)\n",
    "# new_X_seq, _ = create_sequences(new_data_scaled, seq_length)\n",
    "\n",
    "# Reshape input data for LSTM\n",
    "x_test_reshaped = X_test_seq.reshape((X_test_seq.shape[0], X_test_seq.shape[1], X_test_seq.shape[2]))\n",
    "\n",
    "# Evaluate the model\n",
    "loss = model.evaluate(x_test_reshaped, y_test_seq)\n",
    "print(\"Test Loss:\", loss)\n",
    "\n",
    "# Make predictions\n",
    "predictions = model.predict(x_test_reshaped)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-11T20:02:25.350475700Z",
     "start_time": "2024-02-11T20:01:46.048291100Z"
    }
   },
   "id": "2ed92145cdf43e4b",
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Save Model and Export (Optimize for Size)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7b5ce97d3ad60835"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Caiti\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\Caiti\\AppData\\Local\\Temp\\tmp894a0j8b\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\Caiti\\AppData\\Local\\Temp\\tmp894a0j8b\\assets\n"
     ]
    }
   ],
   "source": [
    "# # Model Export\n",
    "# save Keras model\n",
    "model.save(\"model_file_name\" +'.h5')\n",
    "\n",
    "# Convert Keras model to a TensorFlow Lite model \n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "\n",
    "# Disable experimental lowering of tensor list ops\n",
    "converter._experimental_lower_tensor_list_ops = False\n",
    "\n",
    "# Specify to use select TensorFlow ops\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS, tf.lite.OpsSet.SELECT_TF_OPS]\n",
    "\n",
    "# Convert the model\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "# Save the TensorFlow Lite model to a file\n",
    "with open(\"model_file_name.tflite\", 'wb') as f:\n",
    "    f.write(tflite_model)\n",
    "\n",
    "# TODO: see if we can minimize the size of the tflite file in this block "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-11T20:10:22.259893700Z",
     "start_time": "2024-02-11T20:10:18.989384200Z"
    }
   },
   "id": "be97f5b333a0465e",
   "execution_count": 9
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
