{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Long short-term memory (LSTM) for Battery Management System (BMS) State of Charge (SOC) and State of Health (SOH) Estimation\n",
    "\n",
    "<img src=\"../../doc/img/LSTMNetwork.jpg\"\n",
    "     alt=\"Machine Learning Network\"\n",
    "     style=\"fit: left; margin-right: 10px;\"  />"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ede2fd9ea9a82e5"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Import Libraries"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d6a4133cfdb0184d"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# adding new libraries\n",
    "import tensorflow as tf \n",
    "from tensorflow.keras.models import Sequential \n",
    "from tensorflow.keras.layers import Flatten \n",
    "from tensorflow.keras.layers import Dense, Dropout \n",
    "from tensorflow.keras.layers import Activation \n",
    "from tensorflow.keras import layers, Input\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler  \n",
    "from tensorflow.keras.optimizers import Adam\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-10T02:41:03.512205Z",
     "start_time": "2024-02-10T02:41:02.291153500Z"
    }
   },
   "id": "3bb5f57e7bcf1ed4",
   "execution_count": 55
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Import Data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "382394fc93f24d78"
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-02-10T02:41:12.055662400Z",
     "start_time": "2024-02-10T02:41:06.502417400Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "                  V             I           SOC        T_surf           SOH\ncount  1.640946e+06  1.640946e+06  1.640946e+06  1.640946e+06  1.640946e+06\nmean   3.471013e+00  3.610140e+00  4.188879e+01  5.180549e+01  8.566437e+01\nstd    8.445745e-01  2.830966e+01  4.022232e+01  2.451698e+01  9.026790e+00\nmin   -9.394656e-01 -5.500295e+01 -5.753759e+00  2.499965e+01  7.000000e+01\n25%    3.144859e+00 -1.900000e+01  1.230206e+00  2.583835e+01  7.800000e+01\n50%    3.693897e+00  5.000000e+00  3.474387e+01  4.826449e+01  8.600000e+01\n75%    4.064538e+00  2.600000e+01  8.456010e+01  7.304868e+01  9.400000e+01\nmax    4.723157e+00  5.500289e+01  1.070423e+02  1.015903e+02  1.000000e+02",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>V</th>\n      <th>I</th>\n      <th>SOC</th>\n      <th>T_surf</th>\n      <th>SOH</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>1.640946e+06</td>\n      <td>1.640946e+06</td>\n      <td>1.640946e+06</td>\n      <td>1.640946e+06</td>\n      <td>1.640946e+06</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>3.471013e+00</td>\n      <td>3.610140e+00</td>\n      <td>4.188879e+01</td>\n      <td>5.180549e+01</td>\n      <td>8.566437e+01</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>8.445745e-01</td>\n      <td>2.830966e+01</td>\n      <td>4.022232e+01</td>\n      <td>2.451698e+01</td>\n      <td>9.026790e+00</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>-9.394656e-01</td>\n      <td>-5.500295e+01</td>\n      <td>-5.753759e+00</td>\n      <td>2.499965e+01</td>\n      <td>7.000000e+01</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>3.144859e+00</td>\n      <td>-1.900000e+01</td>\n      <td>1.230206e+00</td>\n      <td>2.583835e+01</td>\n      <td>7.800000e+01</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>3.693897e+00</td>\n      <td>5.000000e+00</td>\n      <td>3.474387e+01</td>\n      <td>4.826449e+01</td>\n      <td>8.600000e+01</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>4.064538e+00</td>\n      <td>2.600000e+01</td>\n      <td>8.456010e+01</td>\n      <td>7.304868e+01</td>\n      <td>9.400000e+01</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>4.723157e+00</td>\n      <td>5.500289e+01</td>\n      <td>1.070423e+02</td>\n      <td>1.015903e+02</td>\n      <td>1.000000e+02</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import Data\n",
    "df = pd.read_csv('../../res/model_data/batemo_model_data.csv')\n",
    "df.describe()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Train Test Split"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f43256173a46820c"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1312755, 1, 2)\n",
      "(1312755, 2)\n",
      "(328189, 1, 2)\n",
      "(328189, 2)\n"
     ]
    }
   ],
   "source": [
    "# Define training variables\n",
    "# TODO: need to consider if keeping current (I) is a valuable input feature or not (since the model performs better w/o it)\n",
    "X = df[['V', 'I']].values\n",
    "\n",
    "# LSTM output with 2 nodes (SOH and SOC) \n",
    "Y = df[['SOC', 'SOH']].values\n",
    "\n",
    "# Normalize input data\n",
    "scaler = MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Split the data into training and testing\n",
    "x_train, x_test, y_train, y_test = train_test_split(X_scaled, Y, test_size=0.2, random_state=42)  # use normalized features to prevent over-fitting (X_scaled)\n",
    "\n",
    "# Define function to create sequences\n",
    "# NOTE: The creation of input-output pairs allows the model to learn from historical context. The input sequences serve as a history of past observations, while the corresponding output (target) provides the next observation in the sequence.This historical context is crucial for making accurate predictions, especially in time-series forecasting or sequence prediction tasks where the future state depends on past states\n",
    "def create_sequences(data, seq_length):\n",
    "    X = []\n",
    "    y = []\n",
    "    for i in range(len(data) - seq_length):\n",
    "        X.append(data[i:i + seq_length])  # Features (voltage, current, temperature, state of charge) are turned into a list of historical values \n",
    "        y.append(data[i + seq_length])     # Target variables (SOH and SOC) are turned into a list of historical values \n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# Choose sequence length\n",
    "seq_length = 1 # sequence length set to 1 to take immediate values from sensor reading during testing \n",
    "# NOTE:  Even with seq_length of 1, organizing the data into sequences might provide the model with some historical context. Although the immediate historical context is limited, the model can still potentially learn from patterns and trends in the data over time\n",
    "\n",
    "# Create sequences for training and testing data\n",
    "X_train_seq, y_train_seq = create_sequences(x_train, seq_length)\n",
    "X_test_seq, y_test_seq = create_sequences(x_test, seq_length)\n",
    "\n",
    "print(X_train_seq.shape)\n",
    "print(y_train_seq.shape)\n",
    "print(X_test_seq.shape)\n",
    "print(y_test_seq.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-10T02:41:31.190183Z",
     "start_time": "2024-02-10T02:41:23.724706200Z"
    }
   },
   "id": "fec8c5f154adcc8a",
   "execution_count": 57
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Fit Model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bca6a6d9d787af94"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_18\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_15 (LSTM)              (None, 50)                10600     \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 2)                 102       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10702 (41.80 KB)\n",
      "Trainable params: 10702 (41.80 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      " 4622/41024 [==>...........................] - ETA: 1:23 - loss: 0.0503"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[58], line 16\u001B[0m\n\u001B[0;32m     13\u001B[0m model\u001B[38;5;241m.\u001B[39msummary()\n\u001B[0;32m     15\u001B[0m \u001B[38;5;66;03m# Train the model\u001B[39;00m\n\u001B[1;32m---> 16\u001B[0m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_train_seq\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_train_seq\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m10\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m32\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvalidation_data\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mX_test_seq\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_test_seq\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     18\u001B[0m \u001B[38;5;66;03m# TODO: THINGS TO CONSIDER FOR FINE-TUNING HYPERPARAMETERS\u001B[39;00m\n\u001B[0;32m     19\u001B[0m \u001B[38;5;66;03m# TODO: 1) consider altering the depth of the network. currently we have 1 hidden layer \u001B[39;00m\n\u001B[0;32m     20\u001B[0m \u001B[38;5;66;03m# TODO: 2) consider altering the width of the network. currently there are 50 nodes \u001B[39;00m\n\u001B[0;32m     21\u001B[0m \u001B[38;5;66;03m# TODO: 3) consider altering the activation function. right now it is set to be relu \u001B[39;00m\n\u001B[0;32m     22\u001B[0m \u001B[38;5;66;03m# TODO: 4) consider altering the optimizer. right now it is set to Adam\u001B[39;00m\n\u001B[0;32m     23\u001B[0m \u001B[38;5;66;03m# TODO: 5) consider altering the number of epochs \u001B[39;00m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:65\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     63\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m     64\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m---> 65\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m fn(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m     66\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m     67\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\engine\\training.py:1798\u001B[0m, in \u001B[0;36mModel.fit\u001B[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001B[0m\n\u001B[0;32m   1796\u001B[0m callbacks\u001B[38;5;241m.\u001B[39mon_epoch_begin(epoch)\n\u001B[0;32m   1797\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m data_handler\u001B[38;5;241m.\u001B[39mcatch_stop_iteration():\n\u001B[1;32m-> 1798\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m step \u001B[38;5;129;01min\u001B[39;00m data_handler\u001B[38;5;241m.\u001B[39msteps():\n\u001B[0;32m   1799\u001B[0m         \u001B[38;5;28;01mwith\u001B[39;00m tf\u001B[38;5;241m.\u001B[39mprofiler\u001B[38;5;241m.\u001B[39mexperimental\u001B[38;5;241m.\u001B[39mTrace(\n\u001B[0;32m   1800\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtrain\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m   1801\u001B[0m             epoch_num\u001B[38;5;241m=\u001B[39mepoch,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1804\u001B[0m             _r\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m,\n\u001B[0;32m   1805\u001B[0m         ):\n\u001B[0;32m   1806\u001B[0m             callbacks\u001B[38;5;241m.\u001B[39mon_train_batch_begin(step)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\engine\\data_adapter.py:1411\u001B[0m, in \u001B[0;36mDataHandler.steps\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   1409\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_insufficient_data:  \u001B[38;5;66;03m# Set by `catch_stop_iteration`.\u001B[39;00m\n\u001B[0;32m   1410\u001B[0m     \u001B[38;5;28;01mbreak\u001B[39;00m\n\u001B[1;32m-> 1411\u001B[0m original_spe \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_steps_per_execution\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnumpy\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mitem()\n\u001B[0;32m   1412\u001B[0m can_run_full_execution \u001B[38;5;241m=\u001B[39m (\n\u001B[0;32m   1413\u001B[0m     original_spe \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[0;32m   1414\u001B[0m     \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_inferred_steps \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m   1415\u001B[0m     \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_inferred_steps \u001B[38;5;241m-\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_current_step \u001B[38;5;241m>\u001B[39m\u001B[38;5;241m=\u001B[39m original_spe\n\u001B[0;32m   1416\u001B[0m )\n\u001B[0;32m   1418\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m can_run_full_execution:\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:689\u001B[0m, in \u001B[0;36mBaseResourceVariable.numpy\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    687\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mnumpy\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m    688\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m context\u001B[38;5;241m.\u001B[39mexecuting_eagerly():\n\u001B[1;32m--> 689\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread_value\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mnumpy()\n\u001B[0;32m    690\u001B[0m   \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mNotImplementedError\u001B[39;00m(\n\u001B[0;32m    691\u001B[0m       \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnumpy() is only available when eager execution is enabled.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "# Define model for predicting SOH and SOC \n",
    "model = Sequential()\n",
    "\n",
    "# Defining a model for predicting SOH and SOC\n",
    "model.add(LSTM(50, activation='relu', input_shape=(X_train_seq.shape[1], X_train_seq.shape[2])))\n",
    "\n",
    "model.add(Dense(units=2))  # Output layer for two continuous values: SOC and SOH\n",
    "\n",
    "# Compile model with Adam optimizer and default learning rate\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# NOTE: .summary() is a method used in Keras, a high-level deep learning library, to display a summary of the neural network model's architecture. it will print out the layer name, layer type, output shape, number of parameters and trainable/non-trainable params\n",
    "model.summary()\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train_seq, y_train_seq, epochs=10, batch_size=32, validation_data=(X_test_seq, y_test_seq))\n",
    "\n",
    "# TODO: THINGS TO CONSIDER FOR FINE-TUNING HYPERPARAMETERS\n",
    "# TODO: 1) consider altering the depth of the network. currently we have 1 hidden layer \n",
    "# TODO: 2) consider altering the width of the network. currently there are 50 nodes \n",
    "# TODO: 3) consider altering the activation function. right now it is set to be relu \n",
    "# TODO: 4) consider altering the optimizer. right now it is set to Adam\n",
    "# TODO: 5) consider altering the number of epochs "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-10T02:41:58.262594400Z",
     "start_time": "2024-02-10T02:41:37.512944800Z"
    }
   },
   "id": "940d00ddbf62df1c",
   "execution_count": 58
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Test Model / Predict"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f1eb6fef4085f143"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10256/10256 [==============================] - 29s 3ms/step - loss: 0.1273\n",
      "Test Loss: 0.1272556632757187\n",
      "10256/10256 [==============================] - 34s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "# Preprocess and create sequences for new data\n",
    "# TODO: once loaded onto the microcontroller, new_data will be the sensor reading \n",
    "# new_data_scaled = scaler.transform(new_data)\n",
    "# new_X_seq, _ = create_sequences(new_data_scaled, seq_length)\n",
    "\n",
    "# Reshape input data for LSTM\n",
    "x_test_reshaped = X_test_seq.reshape((X_test_seq.shape[0], X_test_seq.shape[1], X_test_seq.shape[2]))\n",
    "\n",
    "# Evaluate the model\n",
    "loss = model.evaluate(x_test_reshaped, y_test_seq)\n",
    "print(\"Test Loss:\", loss)\n",
    "\n",
    "# Make predictions\n",
    "predictions = model.predict(x_test_reshaped)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-09T20:19:23.928692300Z",
     "start_time": "2024-02-09T20:18:14.410867400Z"
    }
   },
   "id": "2ed92145cdf43e4b",
   "execution_count": 13
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Save Model and Export (Optimize for Size)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7b5ce97d3ad60835"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "be97f5b333a0465e"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
