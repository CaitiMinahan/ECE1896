{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Import Libraries"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d6a4133cfdb0184d"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Caiti\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# adding new libraries\n",
    "import tensorflow as tf \n",
    "from tensorflow.keras.models import Sequential \n",
    "from tensorflow.keras.layers import Flatten \n",
    "from tensorflow.keras.layers import Dense, Dropout \n",
    "from tensorflow.keras.layers import Activation \n",
    "from tensorflow.keras import layers, Input\n",
    "from tensorflow.keras.regularizers import l1, l2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler  # Import MinMaxScaler\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.optimizers import SGD\n",
    "from tensorflow.keras.losses import MeanAbsoluteError\n",
    "from keras.regularizers import l2\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-09T17:48:37.147888200Z",
     "start_time": "2024-02-09T17:48:26.336314800Z"
    }
   },
   "id": "3bb5f57e7bcf1ed4",
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Import Data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "382394fc93f24d78"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-02-09T17:48:41.400103300Z",
     "start_time": "2024-02-09T17:48:39.964061500Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "                  V             I           SOC        T_surf           SOH\ncount  1.640946e+06  1.640946e+06  1.640946e+06  1.640946e+06  1.640946e+06\nmean   3.471013e+00  3.610140e+00  4.188879e+01  5.180549e+01  8.566437e+01\nstd    8.445745e-01  2.830966e+01  4.022232e+01  2.451698e+01  9.026790e+00\nmin   -9.394656e-01 -5.500295e+01 -5.753759e+00  2.499965e+01  7.000000e+01\n25%    3.144859e+00 -1.900000e+01  1.230206e+00  2.583835e+01  7.800000e+01\n50%    3.693897e+00  5.000000e+00  3.474387e+01  4.826449e+01  8.600000e+01\n75%    4.064538e+00  2.600000e+01  8.456010e+01  7.304868e+01  9.400000e+01\nmax    4.723157e+00  5.500289e+01  1.070423e+02  1.015903e+02  1.000000e+02",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>V</th>\n      <th>I</th>\n      <th>SOC</th>\n      <th>T_surf</th>\n      <th>SOH</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>1.640946e+06</td>\n      <td>1.640946e+06</td>\n      <td>1.640946e+06</td>\n      <td>1.640946e+06</td>\n      <td>1.640946e+06</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>3.471013e+00</td>\n      <td>3.610140e+00</td>\n      <td>4.188879e+01</td>\n      <td>5.180549e+01</td>\n      <td>8.566437e+01</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>8.445745e-01</td>\n      <td>2.830966e+01</td>\n      <td>4.022232e+01</td>\n      <td>2.451698e+01</td>\n      <td>9.026790e+00</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>-9.394656e-01</td>\n      <td>-5.500295e+01</td>\n      <td>-5.753759e+00</td>\n      <td>2.499965e+01</td>\n      <td>7.000000e+01</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>3.144859e+00</td>\n      <td>-1.900000e+01</td>\n      <td>1.230206e+00</td>\n      <td>2.583835e+01</td>\n      <td>7.800000e+01</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>3.693897e+00</td>\n      <td>5.000000e+00</td>\n      <td>3.474387e+01</td>\n      <td>4.826449e+01</td>\n      <td>8.600000e+01</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>4.064538e+00</td>\n      <td>2.600000e+01</td>\n      <td>8.456010e+01</td>\n      <td>7.304868e+01</td>\n      <td>9.400000e+01</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>4.723157e+00</td>\n      <td>5.500289e+01</td>\n      <td>1.070423e+02</td>\n      <td>1.015903e+02</td>\n      <td>1.000000e+02</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df = pd.read_csv('../../res/model_data/batemo_model_data.csv')\n",
    "# df = df.drop('SOH', axis=1) # Remove SOH from input data\n",
    "# \n",
    "# # add moving averages of V, I, SOC, and T_surface to the input data\n",
    "# df['V_ma'] = df['V'].rolling(window=10).mean()\n",
    "# df['I_ma'] = df['I'].rolling(window=10).mean()\n",
    "# df['T_surf_ma'] = df['T_surf'].rolling(window=10).mean()\n",
    "# \n",
    "# # drop the first 10 rows of the data since the moving averages are NaN for the first 10 rows\n",
    "# df = df.dropna()\n",
    "# \n",
    "# df\n",
    "\n",
    "# Import Data\n",
    "df = pd.read_csv('../../res/model_data/batemo_model_data.csv')\n",
    "df.describe()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Train Test Split"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f43256173a46820c"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (1312746, 10, 3)\n",
      "y_train shape: (1312746,)\n",
      "X_test shape: (328180, 10, 3)\n",
      "y_test shape: (328180,)\n"
     ]
    },
    {
     "data": {
      "text/plain": "                V          I         SOC      T_surf  SOH\n0        4.200000   0.000000  100.000000   25.000000  100\n1        4.198758  -0.225199  100.000000   25.000000  100\n2        4.197524  -0.449161  100.000000   25.000000  100\n3        4.196296  -0.671867  100.000000   25.000000  100\n4        4.190443  -1.733425  100.000000   25.000000  100\n...           ...        ...         ...         ...  ...\n1640941  3.040704 -41.000000   14.330671   95.558472   70\n1640942  3.019722 -41.000000   13.112293   96.489709   70\n1640943  2.985720 -41.000000   11.355930   97.840139   70\n1640944  2.945987 -41.000000    9.599568   99.207108   70\n1640945  2.899612 -41.000000    7.843205  100.599081   70\n\n[1640946 rows x 5 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>V</th>\n      <th>I</th>\n      <th>SOC</th>\n      <th>T_surf</th>\n      <th>SOH</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>4.200000</td>\n      <td>0.000000</td>\n      <td>100.000000</td>\n      <td>25.000000</td>\n      <td>100</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>4.198758</td>\n      <td>-0.225199</td>\n      <td>100.000000</td>\n      <td>25.000000</td>\n      <td>100</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>4.197524</td>\n      <td>-0.449161</td>\n      <td>100.000000</td>\n      <td>25.000000</td>\n      <td>100</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4.196296</td>\n      <td>-0.671867</td>\n      <td>100.000000</td>\n      <td>25.000000</td>\n      <td>100</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4.190443</td>\n      <td>-1.733425</td>\n      <td>100.000000</td>\n      <td>25.000000</td>\n      <td>100</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1640941</th>\n      <td>3.040704</td>\n      <td>-41.000000</td>\n      <td>14.330671</td>\n      <td>95.558472</td>\n      <td>70</td>\n    </tr>\n    <tr>\n      <th>1640942</th>\n      <td>3.019722</td>\n      <td>-41.000000</td>\n      <td>13.112293</td>\n      <td>96.489709</td>\n      <td>70</td>\n    </tr>\n    <tr>\n      <th>1640943</th>\n      <td>2.985720</td>\n      <td>-41.000000</td>\n      <td>11.355930</td>\n      <td>97.840139</td>\n      <td>70</td>\n    </tr>\n    <tr>\n      <th>1640944</th>\n      <td>2.945987</td>\n      <td>-41.000000</td>\n      <td>9.599568</td>\n      <td>99.207108</td>\n      <td>70</td>\n    </tr>\n    <tr>\n      <th>1640945</th>\n      <td>2.899612</td>\n      <td>-41.000000</td>\n      <td>7.843205</td>\n      <td>100.599081</td>\n      <td>70</td>\n    </tr>\n  </tbody>\n</table>\n<p>1640946 rows Ã— 5 columns</p>\n</div>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define training variables\n",
    "# X = df[['V', 'I', 'T_surf']]\n",
    "# X = df[['V', 'I', 'T_surf', 'SOC']]\n",
    "X = df[['V', 'I', 'T_surf', 'SOC']].values\n",
    "# TODO: may need to add SOC as an input feature for predicting SOH ? \n",
    "\n",
    "# comparing LSTM with 2 nodes at output (SOC and SOH) vs. just 1 node (SOC or SOH)\n",
    "# Y = df[['SOC', 'SOH']]\n",
    "# Y = df[['SOC']]\n",
    "# Y = df[['SOH']]\n",
    "Y = df['SOH'].values\n",
    "\n",
    "# Normalize input data\n",
    "scaler = MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Split the data into training and testing\n",
    "# x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "x_train, x_test, y_train, y_test = train_test_split(X_scaled, Y, test_size=0.2, random_state=42)  # use normalized features to prevent overfitting (X_scaled)\n",
    "\n",
    "# Reshape input data for LSTM\n",
    "# x_train = x_train.values.reshape((x_train.shape[0], x_train.shape[1], 1))\n",
    "# x_test = x_test.values.reshape((x_test.shape[0], x_test.shape[1], 1))\n",
    "\n",
    "\n",
    "# Define function to create sequences\n",
    "def create_sequences(data, seq_length):\n",
    "    X = []\n",
    "    y = []\n",
    "    for i in range(len(data) - seq_length):\n",
    "        X.append(data[i:i + seq_length, :-1])  # Features (voltage, current, temperature, state of charge)\n",
    "        y.append(data[i + seq_length, -1])     # Target variable (state of health)\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# Choose sequence length\n",
    "seq_length = 10 \n",
    "\n",
    "# Create sequences for training and testing data\n",
    "X_train_seq, y_train_seq = create_sequences(x_train, seq_length)\n",
    "X_test_seq, y_test_seq = create_sequences(x_test, seq_length)\n",
    "\n",
    "# Print shapes of train and test data\n",
    "print(\"X_train shape:\", X_train_seq.shape)\n",
    "print(\"y_train shape:\", y_train_seq.shape)\n",
    "print(\"X_test shape:\", X_test_seq.shape)\n",
    "print(\"y_test shape:\", y_test_seq.shape)\n",
    "\n",
    "df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-09T17:54:40.162914200Z",
     "start_time": "2024-02-09T17:54:36.578455Z"
    }
   },
   "id": "fec8c5f154adcc8a",
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Fit Model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bca6a6d9d787af94"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_1 (LSTM)               (None, 50)                10800     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 51        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10851 (42.39 KB)\n",
      "Trainable params: 10851 (42.39 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "41024/41024 [==============================] - 222s 5ms/step - loss: 0.1274 - val_loss: 0.1272\n",
      "Epoch 2/10\n",
      "41024/41024 [==============================] - 208s 5ms/step - loss: 0.1272 - val_loss: 0.1272\n",
      "Epoch 3/10\n",
      "41024/41024 [==============================] - 211s 5ms/step - loss: 0.1272 - val_loss: 0.1272\n",
      "Epoch 4/10\n",
      "41024/41024 [==============================] - 213s 5ms/step - loss: 0.1272 - val_loss: 0.1272\n",
      "Epoch 5/10\n",
      "41024/41024 [==============================] - 215s 5ms/step - loss: 0.1272 - val_loss: 0.1273\n",
      "Epoch 6/10\n",
      "41024/41024 [==============================] - 212s 5ms/step - loss: 0.1272 - val_loss: 0.1272\n",
      "Epoch 7/10\n",
      "41024/41024 [==============================] - 213s 5ms/step - loss: 0.1272 - val_loss: 0.1272\n",
      "Epoch 8/10\n",
      "41024/41024 [==============================] - 214s 5ms/step - loss: 0.1272 - val_loss: 0.1272\n",
      "Epoch 9/10\n",
      "41024/41024 [==============================] - 215s 5ms/step - loss: 0.1272 - val_loss: 0.1273\n",
      "Epoch 10/10\n",
      "41024/41024 [==============================] - 214s 5ms/step - loss: 0.1272 - val_loss: 0.1273\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.src.callbacks.History at 0x1ae86b03d90>"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create an LSTM to train our model for finding SOC/SOH\n",
    "\n",
    "# Define model for predicting SOH or SOC \n",
    "model = Sequential()\n",
    "# model.add(LSTM(50, activation='relu', input_shape=(x_train.shape[1], 1))) # for SOC or SOH \n",
    "\n",
    "# Defining a model for predicting SOH/SOC\n",
    "# model.add(LSTM(50, activation='relu', input_shape=(x_train.shape[1], x_train.shape[2])))\n",
    "# model.add(LSTM(50, activation='relu', input_shape=(x_train.shape[1], x_train.shape[2]), kernel_regularizer=l2(0.01)))\n",
    "model.add(LSTM(50, activation='relu', input_shape=(X_train_seq.shape[1], X_train_seq.shape[2])))\n",
    "\n",
    "# model.add(Dense(2))  # Output layer for two continuous values: SOC and SOH\n",
    "# model.add(Dense(1))  # Output layer for one continuous value: SOC or SOH\n",
    "model.add(Dense(units=1))\n",
    "\n",
    "# Compile model with Adam optimizer and custom learning rate\n",
    "# opt = Adam(learning_rate=0.001)\n",
    "# model.compile(optimizer=opt, loss='mse')  \n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# Train the model\n",
    "# model.fit(x_train, y_train, epochs=5, batch_size=32, validation_data=(x_test, y_test), verbose=2)\n",
    "# model.fit(x_train, y_train, epochs=50, batch_size=32)\n",
    "model.fit(X_train_seq, y_train_seq, epochs=10, batch_size=32, validation_data=(X_test_seq, y_test_seq))\n",
    "\n",
    "# TODO: THINGS TO CONSIDER FOR FINE-TUNING HYPERPARAMETERS\n",
    "# TODO: 1) consider altering the depth of the network. currently we have 1 hidden layer w/ 50 nodes \n",
    "# TODO: 2) consider altering the width of the network. current there are 50 nodes, but that could be fine-tuned \n",
    "# TODO: 3) consider altering the activation function. right now it is set to be relu \n",
    "# TODO: 4) consider altering the optimizier. right now it is set to Adam\n",
    "# TODO: 5) consider altering the number of epochs "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-09T18:40:28.622153600Z",
     "start_time": "2024-02-09T18:04:49.740357900Z"
    }
   },
   "id": "940d00ddbf62df1c",
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Test Model / Predict"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f1eb6fef4085f143"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10256/10256 [==============================] - 29s 3ms/step - loss: 0.1273\n",
      "Test Loss: 0.1272556632757187\n",
      "10256/10256 [==============================] - 34s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "# Reshape input data for LSTM\n",
    "x_test_reshaped = X_test_seq.reshape((X_test_seq.shape[0], X_test_seq.shape[1], X_test_seq.shape[2]))\n",
    "\n",
    "# Evaluate the model\n",
    "loss = model.evaluate(x_test_reshaped, y_test_seq)\n",
    "print(\"Test Loss:\", loss)\n",
    "\n",
    "# Make predictions\n",
    "predictions = model.predict(x_test_reshaped)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-09T20:19:23.928692300Z",
     "start_time": "2024-02-09T20:18:14.410867400Z"
    }
   },
   "id": "2ed92145cdf43e4b",
   "execution_count": 13
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Save Model and Export (Optimize for Size)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7b5ce97d3ad60835"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "be97f5b333a0465e"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
